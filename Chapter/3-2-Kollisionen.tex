\subsection{Collision Detection Monitor}
Im Folgenden wird die Implementierung des Collision Detection
Monitors zur Erkennung von Zusammenstößen zwischen
Roboter und Umgebung dargestellt. Ziel ist es, Kollisionen des
Roboters mit seiner Umgebung festzustellen und darauf basierende Events mit
Geometrieinformationen zur Kollision, Schweregrad und beteiligten
Objekten auszugeben.

\subsubsection{Theoretische Grundlagen der Kollisionserkennung}
Die Kollisionserkennung in Unity basiert auf einem zweistufigen Verfahren, das
von der integrierten PhysX 5.1 Engine implementiert wird
\vglcite{nvidia2024physx5}. In der Broad Phase werden zunächst
Axis-Aligned Bounding Boxes (AABB) aller Objekte auf mögliche Überlappungen
geprüft. Dieser Schritt reduziert die Anzahl der detaillierten Prüfungen von
$O(n^2)$ auf $O(n \log n)$ durch räumliche Partitionierung
\vglcite[14]{ericson2004real}. Nur Objektpaare mit überlappenden Bounding Boxes
werden an die Narrow Phase weitergereicht, wo der präzise
GJK-Algorithmus (Gilbert-Johnson-Keerthi) die tatsächliche Kollision zwischen
konvexen Geometrien ermittelt.\vglcite[399\psqq]{ericson2004real}

Unity3D unterscheidet dabei zwischen physikalischen Kollisionen und
Trigger-Events. Während physikalische Kollisionen Reaktionskräfte berechnen,
detektieren Trigger lediglich Überlappungen und generieren entsprechende Events
\vglcite{unity2025collisions}. Hier kommen lediglich Trigger-Collider
zum Einsatz,
da sich sonst die Umgebung durch physikalische Wechselwirkungen während der
Simulation verändern würde. Die Layer-Matrix ermöglicht zusätzlich
eine selektive
Kollisionserkennung, indem bestimmte Layer-Kombinationen von der Prüfung
ausgeschlossen werden können. Dies reduziert sowohl die Rechenlast als auch
unerwünschte Kollisionsmeldungen zwischen semantisch nicht relevanten Objekten.

\subsubsection{Praktisches Vorgehen}
Für die Kollisionserkennung eines Roboterarms mit sechs Freiheitsgraden müssen
spezielle Anpassungen vorgenommen werden: Da benachbarte Glieder der
kinematischen Kette konstruktionsbedingt immer in Kontakt stehen, würden diese
ohne Filterung kontinuierlich Kollisionen melden. Unity3D ermöglicht mittels
nativer Funktionen der API die Möglichkeit des expliziten Ausschließens
solcher Kollisionspaare.

Das Layer-System wird zur semantischen Trennung verschiedener Objektkategorien
genutzt. Der Roboter operiert auf dem Standard-Layer, während Werkstücke auf
Layer 30 (Parts) und Stationen auf Layer 31 (ProcessFlow) (siehe Kapitel
\ref{section:prozessfolgen}) platziert werden.
Durch Konfiguration der Collision Layer Matrix wird sichergestellt, dass nur
sicherheitsrelevante Kollisionen zwischen Roboter und Hindernissen detektiert
werden, während Process Flow Trigger-Events separat behandelt werden.

\subsubsection{Konkrete Implementierung}
Die Implementierung nutzt Trigger-Collider für berührungslose Detektion. Jedes
Roboterglied erhält einen konvexen Mesh-Collider mit einem dedizierten
Detector-Komponenten. Die Filterung benachbarter Glieder erfolgt
durch hierarchische Analyse der
Roboterstruktur, dargestellt in Abbildung~ \ref{listing:adjacentFrames}.

\begin{figure}[H]
  \inputminted[fontsize=\footnotesize]{csharp}{code-snippets/SetupAdjacentFramesIgnoring.cs}
  \caption{Algorithmus zum Ermitteln kinematisch benachbarter Mesh-Collider}
  \label{listing:adjacentFrames}
\end{figure}

Tritt nun eine Kollision mit einem der vordefinierten Objekte auf, wird die
\texttt{OnRobotPartCollision()}-Methode des Monitors aufgerufen. Diese prüft
zunächst, ob es sich um ein gegriffenes Werkstück handelt – solche Kollisionen
werden ignoriert, da das Werkstück temporär Teil des Roboters ist. Anschließend
wird durch einen Cooldown-Mechanismus verhindert, dass dieselbe Kollision
innerhalb kurzer Zeit mehrfach gemeldet wird.

Die Kollisionserkennung unterscheidet zwischen kritischen und unkritischen
Ereignissen basierend auf konfigurierbaren Tags. Objekte mit Tags wie
\texttt{Machine} oder \texttt{Obstacles} lösen kritische Safety Events aus,
während andere Kollisionen als Warnungen klassifiziert werden. Der Monitor
generiert dabei ein \texttt{SafetyEvent}-Objekt mit vollständigen Metadaten
über die Kollision, einschließlich der beteiligten Roboterglieder, des
Kollisionspunkts in Weltkoordinaten und der Distanz zwischen den Objekten.

Diese Ereignisse werden an den zentralen \texttt{RobotSafetyManager}
weitergeleitet, der sie mit dem aktuellen Roboterzustand anreichert und
entsprechend der konfigurierten Logging-Strategie verarbeitet. Durch diese
Architektur bleibt der Collision Detection Monitor unabh
Robotertyp und kann flexibel in verschiedenen Simulationsszenarien eingesetzt
werden.

Die protokollierten Events bestehen jeweils aus dem Namen des Monitors,
einer textuellen Beschreibung, den beteiligten Objekten sowie einem
Schweregrad (critical oder warning). Diese Struktur ermöglicht eine
klare Einordnung der Ereignisse in Kapitel
\ref{sec:collisionauswertung} des Ergebnisteils.
